{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8762686,"sourceType":"datasetVersion","datasetId":5264447},{"sourceId":185122015,"sourceType":"kernelVersion"},{"sourceId":70538,"sourceType":"modelInstanceVersion","modelInstanceId":58897},{"sourceId":75550,"sourceType":"modelInstanceVersion","modelInstanceId":63470},{"sourceId":75661,"sourceType":"modelInstanceVersion","modelInstanceId":63568},{"sourceId":75727,"sourceType":"modelInstanceVersion","modelInstanceId":63470},{"sourceId":75843,"sourceType":"modelInstanceVersion","modelInstanceId":58897},{"sourceId":75887,"sourceType":"modelInstanceVersion","modelInstanceId":58897},{"sourceId":76241,"sourceType":"modelInstanceVersion","modelInstanceId":58897},{"sourceId":76946,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":58897},{"sourceId":77210,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":58897},{"sourceId":77297,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":58897}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"layernormの実装、擬似的バッチサイズ拡張、消失勾配を起こさないようにする、　GANによる画像生成https://qiita.com/keiji_dl/items/45a5775a361151f9189d\nhttps://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\ngeneralcomv2dだとだめ？layerNormのためにshapeを使いたい。","metadata":{}},{"cell_type":"code","source":"!git init\n!git config --global user.email \"gwsgsgdas@gmail.com\"\n!git config --global user.name \"hayathine\"\n!git remote add origin https://github.com/hayathine/dl_lecture_competition_pub.git\n# !git pull origin event-camera-competition\n!git pull origin develop","metadata":{"execution":{"iopub.status.busy":"2024-07-15T02:08:58.295523Z","iopub.execute_input":"2024-07-15T02:08:58.295945Z","iopub.status.idle":"2024-07-15T02:09:03.958063Z","shell.execute_reply.started":"2024-07-15T02:08:58.295915Z","shell.execute_reply":"2024-07-15T02:09:03.957053Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Reinitialized existing Git repository in /kaggle/working/.git/\nfatal: remote origin already exists.\nremote: Enumerating objects: 362, done.\u001b[K\nremote: Counting objects: 100% (167/167), done.\u001b[K\nremote: Compressing objects: 100% (7/7), done.\u001b[K\nremote: Total 362 (delta 163), reused 161 (delta 160), pack-reused 195\u001b[K\nReceiving objects: 100% (362/362), 67.88 KiB | 7.54 MiB/s, done.\nResolving deltas: 100% (177/177), completed with 4 local objects.\nFrom https://github.com/hayathine/dl_lecture_competition_pub\n * branch            develop    -> FETCH_HEAD\n   fe61f92..e1fd3f1  develop    -> origin/develop\nUpdating fe61f92..e1fd3f1\nFast-forward\n .gitignore                   |   3 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n configs/base.yaml            |   9 \u001b[32m+++\u001b[m\u001b[31m-\u001b[m\n image/memo/1720654695562.png | Bin \u001b[31m0\u001b[m -> \u001b[32m25860\u001b[m bytes\n main.py                      |  90 \u001b[32m+++++++++++++++++++++++++\u001b[m\u001b[31m-----------\u001b[m\n memo.md                      |  32 \u001b[32m+++++++++++++\u001b[m\n notebooks/main.ipynb         |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n src/datasets.py              |  33 \u001b[32m+++++++++\u001b[m\u001b[31m----\u001b[m\n src/models/base.py           | 107 \u001b[32m++++++++++++++++++++++++++++\u001b[m\u001b[31m---------------\u001b[m\n src/models/evflownet.py      |  94 \u001b[32m++++++++++++++++++++++++++++\u001b[m\u001b[31m---------\u001b[m\n 9 files changed, 272 insertions(+), 98 deletions(-)\n create mode 100644 image/memo/1720654695562.png\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install hydra-core　 --upgrade -q\n!pip install hdf5plugin --upgrade -q\n!pip install timm -q\nprint('finished')","metadata":{"execution":{"iopub.status.busy":"2024-07-15T02:09:03.960004Z","iopub.execute_input":"2024-07-15T02:09:03.960319Z","iopub.status.idle":"2024-07-15T02:09:41.765734Z","shell.execute_reply.started":"2024-07-15T02:09:03.960289Z","shell.execute_reply":"2024-07-15T02:09:41.764271Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"finished\n","output_type":"stream"}]},{"cell_type":"code","source":"!ln -s /kaggle/input/dl-last-train/test/test /kaggle/working/data/test\n!ln -s /kaggle/input/dl-last-train/train-001/train /kaggle/working/data/train\n!ls data","metadata":{"execution":{"iopub.status.busy":"2024-07-15T02:09:41.767349Z","iopub.execute_input":"2024-07-15T02:09:41.767692Z","iopub.status.idle":"2024-07-15T02:09:44.785649Z","shell.execute_reply.started":"2024-07-15T02:09:41.767659Z","shell.execute_reply":"2024-07-15T02:09:44.784668Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"ln: failed to create symbolic link '/kaggle/working/data/test/test': Read-only file system\nln: failed to create symbolic link '/kaggle/working/data/train/train': Read-only file system\ntest  train\n","output_type":"stream"}]},{"cell_type":"code","source":"%env HYDRA_FULL_ERROR=1\nload_name = '/kaggle/input/dl_last_model/pytorch/202406242354_1_evflow/8/202407141421_9_bins4drop04batch65.pkl'\nsave_name = 'bins4drop04batch65'\nepochs = 40\ndropout = 0.4\nshuffle = False\ndetail = False\nnum_bins =4\nbatch_size = 5\nbatch_extend = 13\nsequenceRecurrent=False\nlearning_rate = 0.001\n!python main.py batch_extend=$batch_extend train.num_bins=$num_bins sequenceRecurrent=$sequenceRecurrent save_name=$save_name load_name=$load_name train.epochs=$epochs train.dropout=$dropout data_loader.train.shuffle=$shuffle detail=$detail train.initial_learning_rate=$learning_rate data_loader.train.batch_size=$batch_size","metadata":{"execution":{"iopub.status.busy":"2024-07-15T02:09:44.788445Z","iopub.execute_input":"2024-07-15T02:09:44.788816Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"env: HYDRA_FULL_ERROR=1\ndevice: cuda\ntrain data: 2015, test data: 97\n-----Model loaded from /kaggle/input/dl_last_model/pytorch/202406242354_1_evflow/8/202407141421_9_bins4drop04batch65.pkl-----\nlearning_late: 5e-05\n  3%|█▎                                        | 12/403 [00:10<03:20,  1.95it/s]step_update_0_loss: 0.5054772946919168\n  6%|██▌                                       | 25/403 [00:45<20:27,  3.25s/it]step_update_1_loss: 2.205412264115735\n  9%|███▉                                      | 38/403 [01:08<11:35,  1.91s/it]step_update_2_loss: 0.962674998387449\n 13%|█████▎                                    | 51/403 [01:29<07:29,  1.28s/it]step_update_3_loss: 0.7608165388595474\n 16%|██████▋                                   | 64/403 [01:49<10:01,  1.77s/it]step_update_4_loss: 0.8658749458946674\n 19%|████████                                  | 77/403 [02:08<07:13,  1.33s/it]step_update_5_loss: 0.7186668994320764\n 22%|█████████▍                                | 90/403 [02:26<05:59,  1.15s/it]step_update_6_loss: 0.7684263247528799\n 26%|██████████▍                              | 103/403 [02:44<08:38,  1.73s/it]step_update_7_loss: 0.7361627701906539\n 29%|███████████▊                             | 116/403 [03:01<07:02,  1.47s/it]step_update_8_loss: 0.7064605052793926\n 32%|█████████████                            | 129/403 [03:19<05:40,  1.24s/it]step_update_9_loss: 0.7545510827741173\n 35%|██████████████▍                          | 142/403 [03:34<05:36,  1.29s/it]step_update_10_loss: 0.6964639407487898\n 38%|███████████████▊                         | 155/403 [03:55<04:57,  1.20s/it]step_update_11_loss: 0.7052584665862887\n 42%|█████████████████                        | 168/403 [04:07<03:15,  1.20it/s]step_update_12_loss: 0.7684335552215179\n 45%|██████████████████▍                      | 181/403 [04:26<09:43,  2.63s/it]step_update_13_loss: 1.24599794425901\n 48%|███████████████████▋                     | 194/403 [04:50<06:21,  1.82s/it]step_update_14_loss: 1.0526265296207322\n 51%|█████████████████████                    | 207/403 [05:10<04:17,  1.32s/it]step_update_15_loss: 0.6510192693958642\n 55%|██████████████████████▍                  | 220/403 [05:30<04:48,  1.58s/it]step_update_16_loss: 0.6503850010391689\n 58%|███████████████████████▋                 | 233/403 [05:49<04:00,  1.41s/it]step_update_17_loss: 0.700679131304129\n 61%|█████████████████████████                | 246/403 [06:15<05:15,  2.01s/it]step_update_18_loss: 0.8738409513470031\n 64%|██████████████████████████▎              | 259/403 [06:33<03:26,  1.43s/it]step_update_19_loss: 0.7616369847368887\n 67%|███████████████████████████▋             | 272/403 [06:55<03:16,  1.50s/it]step_update_20_loss: 0.6727823451361735\n 71%|████████████████████████████▉            | 285/403 [07:17<02:18,  1.17s/it]step_update_21_loss: 0.6649654935947246\n 74%|██████████████████████████████▎          | 298/403 [07:32<01:22,  1.27it/s]step_update_22_loss: 0.7256809402607257\n 77%|███████████████████████████████▋         | 311/403 [07:50<02:45,  1.80s/it]step_update_23_loss: 0.7761548588288741\n 80%|████████████████████████████████▉        | 324/403 [08:09<02:13,  1.69s/it]step_update_24_loss: 0.8039732576551202\n 84%|██████████████████████████████████▎      | 337/403 [08:24<01:01,  1.08it/s]step_update_25_loss: 0.8578191916107738\n 87%|███████████████████████████████████▌     | 350/403 [08:42<01:26,  1.63s/it]step_update_26_loss: 0.7627227960167986\n 90%|████████████████████████████████████▉    | 363/403 [09:01<00:39,  1.01it/s]step_update_27_loss: 0.8517424375499908\n 93%|██████████████████████████████████████▎  | 376/403 [09:12<00:26,  1.02it/s]step_update_28_loss: 0.5079545752899534\n 97%|███████████████████████████████████████▌ | 389/403 [09:30<00:18,  1.29s/it]step_update_29_loss: 0.5210918852773966\n100%|████████████████████████████████████████▉| 402/403 [09:40<00:01,  1.09s/it]step_update_30_loss: 0.5984262566148264\n100%|█████████████████████████████████████████| 403/403 [09:41<00:00,  1.44s/it]\nepoch:0 batch 402 loss: 0.801102562466877\nfinal_train_loss: 0.4661397613278318\nModel saved to checkpoints/202407151109_0_bins4drop04batch65\nlearning_late: 0.0002875\n  3%|█▎                                        | 12/403 [00:09<03:17,  1.98it/s]step_update_0_loss: 0.49717035761148803\n  6%|██▌                                       | 25/403 [00:41<19:21,  3.07s/it]step_update_1_loss: 2.1992436075758013\n  9%|███▉                                      | 38/403 [01:01<08:36,  1.42s/it]step_update_2_loss: 0.9629312223515977\n 13%|█████▎                                    | 51/403 [01:20<06:39,  1.14s/it]step_update_3_loss: 0.761500796766102\n 16%|██████▋                                   | 64/403 [01:37<08:23,  1.48s/it]step_update_4_loss: 0.8666980079667183\n 19%|████████                                  | 77/403 [01:55<06:51,  1.26s/it]step_update_5_loss: 0.7192654433896754\n 22%|█████████▍                                | 90/403 [02:11<05:04,  1.03it/s]step_update_6_loss: 0.769564945278157\n 26%|██████████▍                              | 103/403 [02:28<09:28,  1.90s/it]step_update_7_loss: 0.7379017231733896\n 29%|███████████▊                             | 116/403 [02:42<05:13,  1.09s/it]step_update_8_loss: 0.7093417466989526\n 32%|█████████████                            | 129/403 [02:59<06:19,  1.39s/it]step_update_9_loss: 0.7619719829716911\n 35%|██████████████▍                          | 142/403 [03:10<03:53,  1.12it/s]step_update_10_loss: 0.6980308116892715\n 38%|███████████████▊                         | 155/403 [03:31<05:07,  1.24s/it]step_update_11_loss: 0.7075923122684006\n 42%|█████████████████                        | 168/403 [03:41<02:45,  1.42it/s]step_update_12_loss: 0.763432365940623\n 45%|██████████████████▍                      | 181/403 [03:57<08:43,  2.36s/it]step_update_13_loss: 1.2422979327502601\n 48%|███████████████████▋                     | 194/403 [04:21<05:30,  1.58s/it]step_update_14_loss: 1.053568175990553\n 51%|█████████████████████                    | 207/403 [04:41<04:33,  1.40s/it]step_update_15_loss: 0.6503961067536304\n 55%|██████████████████████▍                  | 220/403 [05:05<04:47,  1.57s/it]step_update_16_loss: 0.649955528742918\n 58%|███████████████████████▋                 | 233/403 [05:25<04:47,  1.69s/it]step_update_17_loss: 0.7011969043807227\n 61%|█████████████████████████                | 246/403 [05:51<05:10,  1.98s/it]step_update_18_loss: 0.8733555160861451\n 64%|██████████████████████████▎              | 259/403 [06:10<04:25,  1.84s/it]step_update_19_loss: 0.7622594404718881\n 67%|███████████████████████████▋             | 272/403 [06:30<02:39,  1.22s/it]step_update_20_loss: 0.6698683890608914\n 71%|████████████████████████████▉            | 285/403 [06:53<02:22,  1.21s/it]step_update_21_loss: 0.6625576713144844\n 74%|██████████████████████████████▎          | 298/403 [07:08<01:34,  1.11it/s]step_update_22_loss: 0.724282983411247\n 77%|███████████████████████████████▋         | 311/403 [07:26<02:32,  1.66s/it]step_update_23_loss: 0.7753756542775095\n 80%|████████████████████████████████▉        | 324/403 [07:46<02:12,  1.68s/it]step_update_24_loss: 0.8027843953030535\n 84%|██████████████████████████████████▎      | 337/403 [08:00<00:58,  1.12it/s]step_update_25_loss: 0.856930149647754\n 87%|███████████████████████████████████▌     | 350/403 [08:17<01:16,  1.45s/it]step_update_26_loss: 0.7600015084528328\n 90%|████████████████████████████████████▉    | 363/403 [08:37<00:40,  1.02s/it]step_update_27_loss: 0.8483679650499142\n 93%|██████████████████████████████████████▎  | 376/403 [08:48<00:27,  1.03s/it]step_update_28_loss: 0.5065256427900168\n 97%|███████████████████████████████████████▌ | 389/403 [09:05<00:16,  1.14s/it]step_update_29_loss: 0.5190750947828986\n100%|████████████████████████████████████████▉| 402/403 [09:16<00:01,  1.03s/it]step_update_30_loss: 0.6029641219511936\n100%|█████████████████████████████████████████| 403/403 [09:18<00:00,  1.39s/it]\nepoch:1 batch 402 loss: 0.8005293066096713\nfinal_train_loss: 0.4701944726766026\nModel saved to checkpoints/202407151109_1_bins4drop04batch65\nlearning_late: 0.000525\n  3%|█▎                                        | 12/403 [00:09<03:29,  1.87it/s]step_update_0_loss: 0.49721004036305644\n  6%|██▌                                       | 25/403 [00:43<19:46,  3.14s/it]step_update_1_loss: 2.192536084179447\n  9%|███▉                                      | 38/403 [01:05<09:36,  1.58s/it]step_update_2_loss: 0.9552575958778787\n 13%|█████▎                                    | 51/403 [01:26<07:34,  1.29s/it]step_update_3_loss: 0.7620014589895044\n 16%|██████▋                                   | 64/403 [01:44<08:24,  1.49s/it]step_update_4_loss: 0.8667900944216539\n 19%|████████                                  | 77/403 [02:05<08:10,  1.50s/it]step_update_5_loss: 0.7177113243401241\n 22%|█████████▍                                | 90/403 [02:21<05:22,  1.03s/it]step_update_6_loss: 0.768048336534564\n 26%|██████████▍                              | 103/403 [02:39<10:26,  2.09s/it]step_update_7_loss: 0.7387914484649953\n 29%|███████████▊                             | 116/403 [02:54<05:38,  1.18s/it]step_update_8_loss: 0.7080115175257929\n 32%|█████████████                            | 129/403 [03:12<06:37,  1.45s/it]step_update_9_loss: 0.7635632146893057\n 35%|██████████████▍                          | 142/403 [03:25<04:32,  1.04s/it]step_update_10_loss: 0.7025363597485962\n 38%|███████████████▊                         | 155/403 [03:48<05:46,  1.40s/it]step_update_11_loss: 0.7070740820157853\n 42%|█████████████████                        | 168/403 [04:00<03:13,  1.21it/s]step_update_12_loss: 0.7582586974462914\n 45%|██████████████████▍                      | 181/403 [04:27<13:39,  3.69s/it]step_update_13_loss: 1.240218003795544\n 48%|███████████████████▋                     | 194/403 [04:48<04:11,  1.20s/it]step_update_14_loss: 1.054701105992751\n 51%|█████████████████████                    | 207/403 [05:10<05:24,  1.65s/it]step_update_15_loss: 0.6496592873039719\n 55%|██████████████████████▍                  | 220/403 [05:27<03:45,  1.23s/it]step_update_16_loss: 0.6492177940133778\n 58%|███████████████████████▋                 | 233/403 [05:47<04:49,  1.71s/it]step_update_17_loss: 0.7016311019306772\n 61%|█████████████████████████                | 246/403 [06:11<05:04,  1.94s/it]step_update_18_loss: 0.8747340203484671\n 64%|██████████████████████████▎              | 259/403 [06:29<03:43,  1.55s/it]step_update_19_loss: 0.7629160598582557\n 67%|███████████████████████████▋             | 272/403 [06:47<02:37,  1.21s/it]step_update_20_loss: 0.6722633997930625\n 71%|████████████████████████████▉            | 285/403 [07:10<02:13,  1.13s/it]step_update_21_loss: 0.6645655181863243\n 74%|██████████████████████████████▎          | 298/403 [07:24<01:26,  1.22it/s]step_update_22_loss: 0.7253491013520948\n 77%|███████████████████████████████▋         | 311/403 [07:41<02:31,  1.65s/it]step_update_23_loss: 0.7775929126998498\n 80%|████████████████████████████████▉        | 324/403 [07:59<02:13,  1.69s/it]step_update_24_loss: 0.8006111825655144\n 84%|██████████████████████████████████▎      | 337/403 [08:13<00:54,  1.22it/s]step_update_25_loss: 0.8594287030046981\n 87%|███████████████████████████████████▌     | 350/403 [08:29<01:23,  1.58s/it]step_update_26_loss: 0.7593296927221782\n 90%|████████████████████████████████████▉    | 363/403 [08:47<00:35,  1.13it/s]step_update_27_loss: 0.848466761287537\n 93%|██████████████████████████████████████▎  | 376/403 [08:58<00:26,  1.02it/s]step_update_28_loss: 0.5081361199877568\n 97%|███████████████████████████████████████▌ | 389/403 [09:13<00:14,  1.06s/it]step_update_29_loss: 0.5186987005034243\n100%|████████████████████████████████████████▉| 402/403 [09:23<00:00,  1.07it/s]step_update_30_loss: 0.6066993305161446\n100%|█████████████████████████████████████████| 403/403 [09:25<00:00,  1.40s/it]\nepoch:2 batch 402 loss: 0.8003873887244718\nfinal_train_loss: 0.4782123998963609\nModel saved to checkpoints/202407151109_2_bins4drop04batch65\nlearning_late: 0.0007625\n  3%|█▎                                        | 12/403 [00:09<03:19,  1.96it/s]step_update_0_loss: 0.5018912239013458\n  6%|██▌                                       | 25/403 [00:42<19:56,  3.17s/it]step_update_1_loss: 2.1806615992746075\n  9%|███▉                                      | 38/403 [01:03<09:43,  1.60s/it]step_update_2_loss: 0.9650684960213477\n 13%|█████▎                                    | 51/403 [01:23<07:03,  1.20s/it]step_update_3_loss: 0.7670929059727819\n 16%|██████▋                                   | 64/403 [01:40<08:11,  1.45s/it]step_update_4_loss: 0.8674760003006052\n 19%|████████                                  | 77/403 [01:59<06:58,  1.28s/it]step_update_5_loss: 0.7205433313807806\n 22%|█████████▍                                | 90/403 [02:14<05:09,  1.01it/s]step_update_6_loss: 0.7687920080184015\n 26%|██████████▍                              | 103/403 [02:31<09:18,  1.86s/it]step_update_7_loss: 0.7406894667839548\n 29%|███████████▊                             | 116/403 [02:46<05:43,  1.20s/it]step_update_8_loss: 0.711014952460195\n 32%|█████████████                            | 129/403 [03:03<06:13,  1.36s/it]step_update_9_loss: 0.7644028374662941\n 35%|██████████████▍                          | 142/403 [03:15<04:33,  1.05s/it]step_update_10_loss: 0.7081933897541154\n 38%|███████████████▊                         | 155/403 [03:36<05:10,  1.25s/it]step_update_11_loss: 0.7082674996433205\n 42%|█████████████████                        | 168/403 [03:47<03:05,  1.27it/s]step_update_12_loss: 0.7586247497620107\n 45%|██████████████████▍                      | 181/403 [04:05<10:41,  2.89s/it]step_update_13_loss: 1.2425072552881362\n 48%|███████████████████▋                     | 194/403 [04:27<04:59,  1.43s/it]step_update_14_loss: 1.055064306473534\n 51%|█████████████████████                    | 207/403 [04:46<04:46,  1.46s/it]step_update_15_loss: 0.6554109788182961\n 55%|██████████████████████▍                  | 220/403 [05:04<04:03,  1.33s/it]step_update_16_loss: 0.651225194376144\n 58%|███████████████████████▋                 | 233/403 [05:22<04:09,  1.47s/it]step_update_17_loss: 0.704047240757429\n 61%|█████████████████████████                | 246/403 [05:46<04:53,  1.87s/it]step_update_18_loss: 0.8759375987793502\n 64%|██████████████████████████▎              | 259/403 [06:03<03:18,  1.38s/it]step_update_19_loss: 0.7602690911969424\n 67%|███████████████████████████▋             | 272/403 [06:22<02:46,  1.27s/it]step_update_20_loss: 0.6759394914411855\n 71%|████████████████████████████▉            | 285/403 [06:45<02:35,  1.32s/it]step_update_21_loss: 0.6654777576188469\n 74%|██████████████████████████████▎          | 298/403 [06:59<01:23,  1.26it/s]step_update_22_loss: 0.7245719757714971\n 77%|███████████████████████████████▋         | 311/403 [07:16<02:45,  1.80s/it]step_update_23_loss: 0.7967346580502354\n 80%|████████████████████████████████▉        | 324/403 [07:34<02:08,  1.63s/it]step_update_24_loss: 0.8048037487736367\n 84%|██████████████████████████████████▎      | 337/403 [07:48<00:58,  1.13it/s]step_update_25_loss: 0.8631516862497963\n 87%|███████████████████████████████████▌     | 350/403 [08:04<01:19,  1.51s/it]step_update_26_loss: 0.7611591797633607\n 90%|████████████████████████████████████▉    | 363/403 [08:23<00:42,  1.06s/it]step_update_27_loss: 0.8539419681924281\n 93%|██████████████████████████████████████▎  | 376/403 [08:32<00:21,  1.25it/s]step_update_28_loss: 0.5115681676661329\n 97%|███████████████████████████████████████▌ | 389/403 [08:49<00:18,  1.29s/it]step_update_29_loss: 0.5234237152740129\n100%|████████████████████████████████████████▉| 402/403 [08:58<00:00,  1.17it/s]step_update_30_loss: 0.610531606531799\n100%|█████████████████████████████████████████| 403/403 [09:00<00:00,  1.34s/it]\nepoch:3 batch 402 loss: 0.8031769058633069\nfinal_train_loss: 0.4874786327240292\nModel saved to checkpoints/202407151109_3_bins4drop04batch65\nlearning_late: 0.001\n  3%|█▎                                        | 12/403 [00:09<03:19,  1.96it/s]step_update_0_loss: 0.5110598594256893\n  6%|██▌                                       | 25/403 [00:42<19:01,  3.02s/it]step_update_1_loss: 2.1912686966858397\n  9%|███▉                                      | 38/403 [01:04<11:25,  1.88s/it]step_update_2_loss: 0.9725949815810551\n 13%|█████▎                                    | 51/403 [01:23<06:47,  1.16s/it]step_update_3_loss: 0.7780425005021344\n 16%|██████▋                                   | 64/403 [01:41<09:37,  1.70s/it]step_update_4_loss: 0.8692043887427933\n 19%|████████                                  | 77/403 [01:58<05:40,  1.05s/it]step_update_5_loss: 0.7294925036499206\n 22%|█████████▍                                | 90/403 [02:15<05:42,  1.09s/it]step_update_6_loss: 0.7822015732275294\n 26%|██████████▍                              | 103/403 [02:30<07:14,  1.45s/it]step_update_7_loss: 0.7529429145858797\n 29%|███████████▊                             | 116/403 [02:47<06:51,  1.43s/it]step_update_8_loss: 0.7180757866147582\n 32%|█████████████                            | 129/403 [03:04<05:25,  1.19s/it]step_update_9_loss: 0.7751856466318436\n 35%|██████████████▍                          | 142/403 [03:17<05:35,  1.29s/it]step_update_10_loss: 0.7105687650940075\n 38%|███████████████▊                         | 155/403 [03:36<04:49,  1.17s/it]step_update_11_loss: 0.7179690263266648\n 42%|█████████████████                        | 168/403 [03:47<02:59,  1.31it/s]step_update_12_loss: 0.7586595495214172\n 45%|██████████████████▍                      | 181/403 [04:05<09:33,  2.59s/it]step_update_13_loss: 1.2519728069189233\n 48%|███████████████████▋                     | 194/403 [04:29<06:00,  1.72s/it]step_update_14_loss: 1.0604606006486792\n 51%|█████████████████████                    | 207/403 [04:47<03:51,  1.18s/it]step_update_15_loss: 0.6612306942040985\n 55%|██████████████████████▍                  | 220/403 [05:07<04:30,  1.48s/it]step_update_16_loss: 0.6556402727966172\n 58%|███████████████████████▋                 | 233/403 [05:23<03:27,  1.22s/it]step_update_17_loss: 0.7102432680754937\n 61%|█████████████████████████                | 246/403 [05:48<04:44,  1.81s/it]step_update_18_loss: 0.8868098764894446\n 64%|██████████████████████████▎              | 259/403 [06:04<03:17,  1.37s/it]step_update_19_loss: 0.7698904999081944\n 67%|███████████████████████████▋             | 272/403 [06:24<02:59,  1.37s/it]step_update_20_loss: 0.6755059723195441\n 71%|████████████████████████████▉            | 285/403 [06:45<02:38,  1.34s/it]step_update_21_loss: 0.6779390770509685\n 74%|██████████████████████████████▎          | 298/403 [06:59<01:14,  1.40it/s]step_update_22_loss: 0.7291896134572593\n 77%|███████████████████████████████▋         | 311/403 [07:16<02:40,  1.74s/it]step_update_23_loss: 0.7851535087628517\n 80%|████████████████████████████████▉        | 324/403 [07:33<01:45,  1.34s/it]step_update_24_loss: 0.8087230143115713\n 84%|██████████████████████████████████▎      | 337/403 [07:47<00:59,  1.12it/s]step_update_25_loss: 0.8604347190452164\n 87%|███████████████████████████████████▌     | 350/403 [08:03<01:12,  1.36s/it]step_update_26_loss: 0.7616144625795241\n 90%|████████████████████████████████████▉    | 363/403 [08:22<00:40,  1.00s/it]step_update_27_loss: 0.8540745130926807\n 93%|██████████████████████████████████████▎  | 376/403 [08:31<00:21,  1.26it/s]step_update_28_loss: 0.5113941014504657\n 97%|███████████████████████████████████████▌ | 389/403 [08:48<00:17,  1.22s/it]step_update_29_loss: 0.5214197770410596\n100%|████████████████████████████████████████▉| 402/403 [08:57<00:00,  1.18it/s]step_update_30_loss: 0.6210383276601242\n100%|█████████████████████████████████████████| 403/403 [08:59<00:00,  1.34s/it]\nepoch:4 batch 402 loss: 0.8087097193032982\nfinal_train_loss: 0.49777672809541884\nModel saved to checkpoints/202407151109_4_bins4drop04batch65\nlearning_late: 0.0009986128001799076\n  3%|█▎                                        | 12/403 [00:09<03:17,  1.98it/s]step_update_0_loss: 0.5081143945583535\n  6%|██▌                                       | 25/403 [00:42<21:14,  3.37s/it]step_update_1_loss: 2.1749767149157035\n  9%|███▉                                      | 38/403 [01:03<08:52,  1.46s/it]step_update_2_loss: 0.9687620457639793\n 13%|█████▎                                    | 51/403 [01:23<06:40,  1.14s/it]step_update_3_loss: 0.7763121824045403\n 16%|██████▋                                   | 64/403 [01:41<08:04,  1.43s/it]step_update_4_loss: 0.8768077651326467\n 19%|████████                                  | 77/403 [01:59<07:09,  1.32s/it]step_update_5_loss: 0.7217246988822338\n 22%|█████████▍                                | 90/403 [02:15<05:10,  1.01it/s]step_update_6_loss: 0.7713022811573828\n 26%|██████████▍                              | 103/403 [02:31<09:12,  1.84s/it]step_update_7_loss: 0.7413677204007487\n 29%|███████████▊                             | 116/403 [02:45<05:37,  1.18s/it]step_update_8_loss: 0.7097654407472672\n 32%|█████████████                            | 129/403 [03:02<06:08,  1.34s/it]step_update_9_loss: 0.7687402275423878\n 35%|██████████████▍                          | 142/403 [03:14<04:16,  1.02it/s]step_update_10_loss: 0.7089678605522972\n 38%|███████████████▊                         | 155/403 [03:35<04:51,  1.18s/it]step_update_11_loss: 0.7097936405802916\n 42%|█████████████████                        | 168/403 [03:45<02:51,  1.37it/s]step_update_12_loss: 0.7512645765645445\n 45%|██████████████████▍                      | 181/403 [04:03<10:02,  2.71s/it]step_update_13_loss: 1.247636197521519\n 48%|███████████████████▋                     | 194/403 [04:24<05:05,  1.46s/it]step_update_14_loss: 1.0609604679803115\n 51%|█████████████████████                    | 207/403 [04:43<04:23,  1.34s/it]step_update_15_loss: 0.6562800636319607\n 55%|██████████████████████▍                  | 220/403 [05:01<04:07,  1.35s/it]step_update_16_loss: 0.6541726989098428\n 58%|███████████████████████▋                 | 233/403 [05:19<04:12,  1.48s/it]step_update_17_loss: 0.7038420862350693\n 61%|█████████████████████████                | 246/403 [05:44<05:09,  1.97s/it]step_update_18_loss: 0.8623301205689814\n 64%|██████████████████████████▎              | 259/403 [06:01<03:56,  1.64s/it]step_update_19_loss: 0.7654080925541352\n 67%|███████████████████████████▋             | 272/403 [06:19<02:28,  1.13s/it]step_update_20_loss: 0.6729909817066287\n 71%|████████████████████████████▉            | 285/403 [06:42<02:43,  1.39s/it]step_update_21_loss: 0.6610467660214205\n 74%|██████████████████████████████▎          | 298/403 [06:56<01:16,  1.36it/s]step_update_22_loss: 0.7270143085875529\n 77%|███████████████████████████████▋         | 311/403 [07:12<02:35,  1.69s/it]step_update_23_loss: 0.7824069042635535\n 80%|████████████████████████████████▉        | 324/403 [07:30<02:12,  1.68s/it]step_update_24_loss: 0.7991074496119288\n 84%|██████████████████████████████████▎      | 337/403 [07:43<00:56,  1.18it/s]step_update_25_loss: 0.85859509471868\n 87%|███████████████████████████████████▌     | 350/403 [07:59<01:22,  1.56s/it]step_update_26_loss: 0.7578069473999111\n 90%|████████████████████████████████████▉    | 363/403 [08:18<00:34,  1.15it/s]step_update_27_loss: 0.8335679126144758\n 93%|██████████████████████████████████████▎  | 376/403 [08:28<00:23,  1.17it/s]step_update_28_loss: 0.5077730031248703\n 97%|███████████████████████████████████████▌ | 389/403 [08:43<00:16,  1.16s/it]step_update_29_loss: 0.5200313907903646\n100%|████████████████████████████████████████▉| 402/403 [08:53<00:00,  1.06it/s]step_update_30_loss: 0.6143994555982211\n100%|█████████████████████████████████████████| 403/403 [08:54<00:00,  1.33s/it]\nepoch:5 batch 402 loss: 0.8023635319690915\nfinal_train_loss: 0.49521444420910055\nModel saved to checkpoints/202407151109_5_bins4drop04batch65\nlearning_late: 0.000994459753267812\n  3%|█▎                                        | 12/403 [00:09<03:18,  1.97it/s]step_update_0_loss: 0.5089096400425287\n  6%|██▌                                       | 25/403 [00:41<18:47,  2.98s/it]step_update_1_loss: 2.1727653514032186\n  9%|███▉                                      | 38/403 [01:01<09:17,  1.53s/it]step_update_2_loss: 0.966038904066357\n 13%|█████▎                                    | 51/403 [01:21<07:08,  1.22s/it]step_update_3_loss: 0.7694485302121351\n 16%|██████▋                                   | 64/403 [01:37<07:42,  1.36s/it]step_update_4_loss: 0.8668784585245999\n 19%|████████                                  | 77/403 [01:56<07:19,  1.35s/it]step_update_5_loss: 0.7154383697287502\n 22%|█████████▍                                | 90/403 [02:11<04:59,  1.05it/s]step_update_6_loss: 0.7707718308964578\n 26%|██████████▍                              | 103/403 [02:28<09:18,  1.86s/it]step_update_7_loss: 0.7472008113184044\n 29%|███████████▊                             | 116/403 [02:42<05:25,  1.13s/it]step_update_8_loss: 0.7044242795555413\n 32%|█████████████                            | 129/403 [02:59<05:57,  1.31s/it]step_update_9_loss: 0.7698294735917819\n 35%|██████████████▍                          | 142/403 [03:10<04:03,  1.07it/s]step_update_10_loss: 0.7088451813031641\n 38%|███████████████▊                         | 155/403 [03:31<05:07,  1.24s/it]step_update_11_loss: 0.7144057873077317\n 42%|█████████████████                        | 168/403 [03:42<02:52,  1.36it/s]step_update_12_loss: 0.7533234171054434\n 43%|█████████████████▍                       | 172/403 [03:44<02:03,  1.87it/s]","output_type":"stream"}]},{"cell_type":"code","source":"# 予測用\n%env HYDRA_FULL_ERROR=1\n# dir_name = '/kaggle/input/dl_last_model/pytorch/202406242354_1_evflow/6/'\ndir_name = 'checkpoints/'\nfile_name = '202407132050_12_bins4_batch88.pkl'\nload_name = dir_name+file_name\nsave_name = 'drop04'\nepochs = 1\ndropout = 0.0\nshuffle = False\ndetail = False\nnum_bins =4\nbatch_size = 5\nbatch_extend = 13\nsequenceRecurrent=False\nlearning_rate = 0.001\n!python main.py batch_extend=$batch_extend train.num_bins=$num_bins sequenceRecurrent=$sequenceRecurrent save_name=$save_name load_name=$load_name train.epochs=$epochs train.dropout=$dropout data_loader.train.shuffle=$shuffle detail=$detail train.initial_learning_rate=$learning_rate data_loader.train.batch_size=$batch_size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checkpoints/pthをダウンロード\nfrom IPython.display import FileLinks \nFileLinks(\"checkpoints\")\n# Dl_last_modelに加える","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # submission\nfrom IPython.display import FileLink\nFileLink(\"submission.npy\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install kagglehub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import kagglehub\nfrom kagglehub.config import get_kaggle_credentials\nkagglehub.login()\n\n# Replace with path to directory containing model files.\nLOCAL_MODEL_DIR = 'path/to/files'\n\nkagglehub.model_upload(\n  handle = 'fewfwfwas/dl_last_model/pyTorch/202406242354_1_evflow',\n  local_model_dir = LOCAL_MODEL_DIR,\n  version_notes = 'Update 2024-07-14')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# hydraの使い方\n\nhttps://zenn.dev/gesonanko/articles/417d43669cf2af\n\n### gettingstarted\n\nhttps://hydra.cc/docs/intro/\n\n#### 2024年6月25日12:19\n\nlossが増えている→過学習？\n\ndropoutを実装する→lossが増加する\n\n#### 2024年6月25日13:28\n\ntrainデータの中身を確認する\n\n#### 2024年6月27日\n\nバッチの擬似的拡張\nhttps://kozodoi.me/blog/20210219/gradient-accumulation\n\n    for x, _ in train_dl:\n        step_count += 1\n        model.train()\n        x = x.to(device)\n\n    rec_img, mask = model(x)\n        train_loss = torch.mean((rec_img - x) ** 2 * mask) / config[\"mask_ratio\"]\n        train_loss.backward()\n\n    if step_count % 8 == 0:  # 8イテレーションごとに更新することで，擬似的にバッチサイズを大きくしている\n            optimizer.step()\n            optimizer.zero_grad()\n\n    total_train_loss += train_loss.item()\n\n多分勾配消失を起こしているので修正する。\nlossをバッチサイズで割っていないことが問題だった。\n\n- 異なるスケールでのロスを足し合わせる．\n  - ベースラインモデルはUNet構造なので，デコーダーの中間層の出力は最終的な出力サイズの0.5,0.25,...倍になっています．各中間層の出力を用いてロスを計算することで，勾配消失を防ぎ，性能向上が見込めます．\n  →F.interpolateでアップサイズ出来そう\n\ndataのpickle化によるロード短縮化\nhttps://hyper-pigeon.hatenablog.com/entry/2021/08/04/225814\n\n#### 2024/06/29\n\n勾配クリッピングは活用できる？DL第六回\nhttps://www.toolify.ai/ja/ai-news-jp/%E5%8B%BE%E9%85%8D%E5%8B%BE%E9%85%8D%E7%88%86%E7%99%BA%E7%9A%84%E5%A2%97%E5%8A%A0%E5%AF%BE%E5%87%A6%E6%B3%95-1122267\nsoftmaxの勾配が小さくなるのを防ぐためで,Scaled Dot-Product\nAttentionと呼ばれる.\n\nGANによる画像生成　第10回\n画像が疎なため無理と思う\n#### 2024/07/08\nlayernormの実装\n\n・時系列画像の差を学習\n・Validの利用","metadata":{}}]}